{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Python3\n",
    "2. Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import copy\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "class Loader:\n",
    "    \n",
    "    def unpickle(self,file):\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "        return dict\n",
    "    \n",
    "    def load_train_data(self):\n",
    "        '''\n",
    "        loads training data: 50,000 examples with 3072 features\n",
    "        '''\n",
    "        X_train = None\n",
    "        Y_train = None\n",
    "        for i in range(1, 6):\n",
    "            pickleFile = self.unpickle('cifar-10-batches-py/data_batch_{}'.format(i))\n",
    "            dataX = pickleFile[b'data']\n",
    "            dataY = pickleFile[b'labels']\n",
    "            \n",
    "            if type(X_train) is np.ndarray:\n",
    "                \n",
    "                X_train = np.concatenate((X_train, dataX))\n",
    "                Y_train = np.concatenate((Y_train, dataY))\n",
    "            else:\n",
    "                \n",
    "                X_train = dataX\n",
    "                Y_train = dataY\n",
    "        \n",
    "        X_train = X_train.reshape([50000, 3, 32, 32])\n",
    "        X_train = X_train.astype(np.float32)\n",
    "        \n",
    "        X_train[:,0,:,:] = (X_train[:,0,:,:] - np.mean(X_train[:,0,:,:])) / np.std(X_train[:,0,:,:])\n",
    "        X_train[:,1,:,:] = (X_train[:,1,:,:] - np.mean(X_train[:,1,:,:])) / np.std(X_train[:,1,:,:])\n",
    "        X_train[:,2,:,:] = (X_train[:,2,:,:] - np.mean(X_train[:,2,:,:])) / np.std(X_train[:,2,:,:])\n",
    "\n",
    "        \n",
    "        Y_train = Y_train.reshape(Y_train.shape[0], 1)\n",
    "\n",
    "        return X_train, Y_train.reshape((50000,))\n",
    "\n",
    "    def load_test_data(self):\n",
    "        '''\n",
    "        loads testing data: 10,000 examples with 3072 features\n",
    "        '''\n",
    "        X_test = None\n",
    "        Y_test = None\n",
    "        pickleFile = self.unpickle('cifar-10-batches-py/test_batch')\n",
    "        dataX = pickleFile[b'data']\n",
    "        dataY = pickleFile[b'labels']\n",
    "        if type(X_test) is np.ndarray:\n",
    "            X_test = np.concatenate((X_test, dataX))\n",
    "            Y_test = np.concatenate((Y_test, dataY))\n",
    "        else:\n",
    "            X_test = np.array(dataX)\n",
    "            Y_test = np.array(dataY)\n",
    "\n",
    "        X_test = X_test.reshape([10000, 3, 32, 32])\n",
    "        X_test = X_test.astype(np.float32)\n",
    "        \n",
    "        X_test[:,0,:,:] = (X_test[:,0,:,:] - np.mean(X_test[:,0,:,:])) / np.std(X_test[:,0,:,:])\n",
    "        X_test[:,1,:,:] = (X_test[:,1,:,:] - np.mean(X_test[:,1,:,:])) / np.std(X_test[:,1,:,:])\n",
    "        X_test[:,2,:,:] = (X_test[:,2,:,:] - np.mean(X_test[:,2,:,:])) / np.std(X_test[:,2,:,:])\n",
    "\n",
    "        \n",
    "        Y_test = Y_test.reshape(Y_test.shape[0], 1)\n",
    "\n",
    "        return X_test, Y_test.reshape((10000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train: (50000, 3, 32, 32) -> 3 examples, 50000 features\n",
      "X_Test: (10000, 3, 32, 32) -> 3 examples, 10000 features\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train = Loader().load_train_data()\n",
    "X_test, Y_test= Loader().load_test_data()\n",
    "\n",
    "print(\"X_Train: {} -> {} examples, {} features\".format(X_train.shape, X_train.shape[1], X_train.shape[0]))\n",
    "print(\"X_Test: {} -> {} examples, {} features\".format(X_test.shape, X_test.shape[1], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = X_train.copy()\n",
    "y_train = Y_train.copy()\n",
    "\n",
    "x_train = torch.from_numpy(x_train)  \n",
    "y_train = torch.from_numpy(y_train) \n",
    "\n",
    "x_test = X_test.copy()\n",
    "y_test = Y_test.copy()\n",
    "\n",
    "x_test = torch.from_numpy(x_test)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "train = []\n",
    "valid = []\n",
    "for i in range(50000):\n",
    "    U = np.random.uniform()\n",
    "    if U <= 0.2:\n",
    "        valid.append((x_train[i],y_train[i]))\n",
    "    else:\n",
    "        train.append((x_train[i],y_train[i]))\n",
    "    \n",
    "test = []\n",
    "for i in range(10000):\n",
    "    test.append((x_test[i], y_test[i]))\n",
    "    \n",
    "trainloader = torch.utils.data.DataLoader(train, batch_size=20,  \n",
    "                                          shuffle=True, num_workers=2)  \n",
    "\n",
    "validloader = torch.utils.data.DataLoader(valid, batch_size=20,  \n",
    "                                          shuffle=True, num_workers=2) \n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test, batch_size=20,  \n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable  \n",
    "import torch.nn as nn  \n",
    "import torch.nn.functional as F  \n",
    "  \n",
    "class Net(nn.Module):               \n",
    "    def __init__(self):      \n",
    "        super(Net, self).__init__()           \n",
    "        self.conv1 = nn.Conv2d(3, 32, 5)   \n",
    "        self.pool = nn.MaxPool2d(2) \n",
    "        self.conv2 = nn.Conv2d(32, 64, 5)  \n",
    "        self.avgpool = nn.AvgPool2d(2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 32, 3)\n",
    "        \n",
    "        self.fc1 = nn.Linear(32 * 3 * 3, 200) \n",
    "        self.fc2 = nn.Linear(200, 100) \n",
    "        self.fc3 = nn.Linear(100, 10) \n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(200)\n",
    "        self.bn2 = nn.BatchNorm2d(100)\n",
    "\n",
    " # 12， 32， 200， 100\n",
    "    def forward(self, x):                \n",
    "                                         \n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.avgpool(F.relu(self.conv2(x)))\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.view(-1, 32 * 3 * 3)   \n",
    "                                    \n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x, dim = 1)\n",
    "        return x  \n",
    "\n",
    "net = Net()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim        \n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.003, momentum=0.9)   \n",
    "loss_plot = []\n",
    "vali_loss = []\n",
    "train_acc = []\n",
    "lr=0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(20):  \n",
    "    losstrack = 0.0\n",
    "    \n",
    "    for i, data in enumerate(trainloader, 0): \n",
    "        inputs, labels = data   \n",
    "        inputs, labels = Variable(inputs), Variable(labels)   \n",
    "                                                        \n",
    "        optimizer.zero_grad()                  \n",
    "        outputs = net(inputs)                \n",
    "        loss = F.nll_loss(outputs, labels)\n",
    "        loss.backward()                     \n",
    "        optimizer.step()                   \n",
    "   \n",
    "        losstrack += loss.data[0] \n",
    "        if i % 1000 == 999:    \n",
    "            print(\"epoch \", epoch + 1, \"iteration \", i, \"loss \", losstrack / 1000)\n",
    "            loss_plot.append(losstrack/1000)\n",
    "            losstrack = 0.0 \n",
    "            \n",
    "            valiloss = 0.0  \n",
    "            c = 0\n",
    "            for j, data in enumerate(validloader, 0):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "                outputs = net(inputs)                \n",
    "                loss = F.nll_loss(outputs, labels)\n",
    "                valiloss += loss.data[0]\n",
    "                c += 1\n",
    "            vali_loss.append(valiloss/c)\n",
    "            valiloss = 0.0\n",
    "              \n",
    "    if epoch % 3 == 2:  \n",
    "        lr *= 0.9\n",
    "        optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n",
    "        \n",
    "        \n",
    "    correct = 0   \n",
    "    total = 0     \n",
    "    for data in trainloader: \n",
    "        x, y = data  \n",
    "        outputs = net(Variable(x)) \n",
    "        _, predicted = torch.max(outputs.data, 1)  \n",
    "        total += y.size(0)         \n",
    "        correct += (predicted == y).sum() \n",
    "        \n",
    "    train_acc.append(100 * correct / total)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
